{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torchvision.models import resnet50, ResNet50_Weights, alexnet, AlexNet_Weights, efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "\n",
    "# Custom imports\n",
    "import transformers\n",
    "from cnn import *\n",
    "from helper_functions import print_train_time\n",
    "\n",
    "# LOG Import\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "PATH = \"/home/fergus/work/data/raiox/classified\"\n",
    "TEST_PATH = \"/home/fergus/work/data/raiox/test\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "SEED = 13\n",
    "LEARNING_RATE = 0.00004\n",
    "NUM_CLASS = 2\n",
    "SIZE = (227, 227) # Usado apenas para o modelo AlexNet construido e n√£o importado\n",
    "GRAYSCALE = False\n",
    "MODEL = \"AlexNet\"\n",
    "\n",
    "print(PATH)\n",
    "print(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save, prepare, configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model_name, model):\n",
    "    # Save the model\n",
    "    if model_name == \"AlexNetConstruida\":\n",
    "        torch.save(model.state_dict(), \"AlexnetConstruida.pth\")\n",
    "    if model_name == \"AlexNet\":\n",
    "        torch.save(model.state_dict(), \"Alexnet.pth\")\n",
    "    elif model_name == \"Resnet50\":\n",
    "        torch.save(model.state_dict(), \"Resnet.pth\")\n",
    "    elif model_name == \"Efficient_V2_S\":\n",
    "        torch.save(model.state_dict(), \"Efficient_V2_S.pth\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), \"default.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(transform = None):\n",
    "\n",
    "    ### Create dataset from a specific PATH\n",
    "    raw_dataset = datasets.ImageFolder(root=PATH,\n",
    "                                       # If pre-treined trasnform use pre-treined.\n",
    "                                       transform=transform if transform else transformers.train_transform(size=SIZE, grayscale=GRAYSCALE),\n",
    "                                       target_transform=None)\n",
    "    print(\"\\nMetadata of dataset:\")\n",
    "    print(f\"Dataset classes: {raw_dataset.classes}\")\n",
    "\n",
    "    # Calculate train and test split\n",
    "    train_size = int(0.9 * len(raw_dataset))\n",
    "    valid_size = len(raw_dataset) - train_size\n",
    "    print(f\"Tot imgs to train: {train_size}\")\n",
    "    print(f\"Tot imgs to valid: {valid_size}\")\n",
    "\n",
    "    ### Create DataLoader\n",
    "    print(\"-----------------------\")\n",
    "    print(\"\\nDataset loaded:\")\n",
    "    torch.manual_seed(seed=SEED)\n",
    "    train_dataloader, valid_dataloader = random_split(raw_dataset, [train_size, valid_size])\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    train_dataloader = DataLoader(dataset=train_dataloader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    print(train_dataloader.dataset)\n",
    "    print(\"\\n----------------------------------------------------------------------------------\")\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataloader, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print(valid_dataloader.dataset)\n",
    "    print(\"\\n----------------------------------------------------------------------------------\")\n",
    "    \n",
    "    print(f\"Tot batchs to train: {len(train_dataloader)} | Tot batchs to test: {len(valid_dataloader)}\\n\")\n",
    "\n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configureModel(model_name, device):\n",
    "    ### Model load / creation\n",
    "    if model_name == \"AlexNetConstruida\":\n",
    "        model = AlexNet(num_classes=NUM_CLASS).to(device)\n",
    "        input_size = (3, 96, 96)\n",
    "    \n",
    "    if model_name == \"AlexNet\":\n",
    "        model               = torch.hub.load(\"pytorch/vision\", \n",
    "                                     \"alexnet\", \n",
    "                                     weights = \"DEFAULT\").to(device)\n",
    "        model.classifier[1] = torch.nn.Linear(9216,4096).to(device)\n",
    "        model.classifier[4] = torch.nn.Linear(4096,1024).to(device)\n",
    "        model.classifier[6] = torch.nn.Linear(1024,2).to(device)\n",
    "\n",
    "        transform = AlexNet_Weights.DEFAULT.transforms()\n",
    "        input_size = (3, 64, 64)\n",
    "\n",
    "    elif model_name == \"Resnet50\": # Pre-treined model\n",
    "        # Using pretrained weights:\n",
    "        model = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n",
    "        model.fc = nn.Linear(2048, NUM_CLASS)\n",
    "        model.to(device)\n",
    "        transform = ResNet50_Weights.DEFAULT.transforms()\n",
    "        input_size = (3, 64, 64)\n",
    "\n",
    "    elif model_name == \"Efficient_V2_S\":\n",
    "        model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT).to(device)\n",
    "        model.classifier = nn.Linear(1280, NUM_CLASS).to(device)\n",
    "        transform = EfficientNet_V2_S_Weights.DEFAULT.transforms()\n",
    "        input_size = (3, 384, 384)\n",
    "\n",
    "    return {\"model\": model, \"transform\": transform, \"input_size\": input_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, criterion, model, train_dataloader, valid_dataloader, device):\n",
    "\n",
    "    total_step = len(train_dataloader)\n",
    "    bacc = torchmetrics.classification.BinaryAccuracy().to(device)\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):  \n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(epoch+1, EPOCHS, i+1, total_step, loss.item()))\n",
    "                \n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in valid_dataloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                bacc(predicted, labels)\n",
    "                del images, labels, outputs\n",
    "            print(f\"Accuracy of the network on the 659 validation images: {bacc.compute() * 100} %\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, transform, device):\n",
    "    # Get test dataset!\n",
    "    test_dataset = datasets.ImageFolder(root=TEST_PATH,\n",
    "                                       # If pre-treined trasnform use pre-treined.\n",
    "                                       transform=transform if transform else transformers.train_transform(size=SIZE, grayscale=GRAYSCALE))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    print(f\"Tot batchs to Evalute: {len(test_loader)} | Tot images to evaluate: {len(test_dataset)}\\n\")\n",
    "\n",
    "    # Set model as evaluation model\n",
    "    model.eval()\n",
    "    # Create metrics\n",
    "    bacc   = torchmetrics.classification.BinaryAccuracy().to(device)\n",
    "    bcm    = torchmetrics.classification.BinaryConfusionMatrix().to(device)\n",
    "    auroc  = torchmetrics.classification.BinaryAUROC().to(device)\n",
    "    bap   = torchmetrics.classification.BinaryAveragePrecision(validate_args=False).to(device)\n",
    "    bacc_arr = []\n",
    "    auroc_arr = []\n",
    "    bap_arr = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Calculate metrics\n",
    "            acc = bacc(predicted, labels)\n",
    "            auc = auroc(predicted, labels)\n",
    "            p = bap(predicted, labels)\n",
    "            bcm(predicted, labels)            \n",
    "            \n",
    "            auroc_arr.append(auc)\n",
    "            bacc_arr.append(acc)\n",
    "            bap_arr.append(p)\n",
    "            del images, labels, outputs\n",
    "    \n",
    "    # Log metrics and plot visuals\n",
    "    print(((f\"\"\"Final Evaluation Metrics:\n",
    "          \\n Accuracy: {bacc.compute()} \n",
    "          \\n Precision: {bap.compute()}\n",
    "          \\n Confusion Matrix: {bcm.compute() * 100} \n",
    "          \\n AUC ROC: {auroc.compute()}\"\"\")))\n",
    "    \n",
    "    bacc_fig, bacc_ax = bacc.plot(bacc_arr)\n",
    "    print(bacc_fig, bacc_ax)\n",
    "\n",
    "    bcm_fig, bcm_ax = bcm.plot()\n",
    "    print(bcm_fig, bcm_ax)\n",
    "  \n",
    "    auroc_fig, auroc_ax = auroc.plot(auroc_arr)\n",
    "    print(auroc_fig, auroc_ax)\n",
    "\n",
    "    p_fig, p_ax = bap.plot(bap_arr)\n",
    "    print(p_fig, p_ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    start_time = timer()\n",
    "\n",
    "    # Get the device\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(\"-----------------------\")\n",
    "    print(f\"Device which will process the data: {device}\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    # Get our model configurations\n",
    "    output = configureModel(MODEL, device)\n",
    "    model = output[\"model\"]\n",
    "    transform = output[\"transform\"]\n",
    "    input_size = output[\"input_size\"]\n",
    "    \n",
    "    ### Prepare and load our data\n",
    "    train_dataloader, valid_dataloader = prepare_data(transform)\n",
    "\n",
    "    ### Print out the model params\n",
    "    print(model.parameters)\n",
    "    print(summary(model, input_size))\n",
    "\n",
    "    if True:\n",
    "        # Define loss function and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        ### Adam optimizer\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                            lr=LEARNING_RATE, \n",
    "                            weight_decay=0.005)\n",
    "\n",
    "        # Train\n",
    "        train(optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            model=model, \n",
    "            train_dataloader=train_dataloader,\n",
    "            valid_dataloader=valid_dataloader,\n",
    "            device=device)\n",
    "\n",
    "        # Save the treined model.\n",
    "        saveModel(MODEL, model)\n",
    "\n",
    "        ### Calculate training time\n",
    "        end_time = timer()\n",
    "        print_train_time(start=start_time, end=end_time, device=device)\n",
    "\n",
    "        print(f\"model loaded: {MODEL}\")\n",
    "\n",
    "        # See how our model performs on unseen data\n",
    "        test(model, transform, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process()\n",
    "torch.manual_seed(seed=SEED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-mba-torch200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
